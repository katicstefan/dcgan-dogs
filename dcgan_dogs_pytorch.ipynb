{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan-dogs-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l92DWDmXyTbS"
      },
      "source": [
        "# Dataset - Generative Dog Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tagQT-ztyMGN",
        "outputId": "6caad20c-98d0-4e51-8db1-8962259cc54c"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p\" -O data.zip && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-25 13:46:26--  https://docs.google.com/uc?export=download&confirm=UchH&id=1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.2.138, 142.251.2.101, 142.251.2.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-84-docs.googleusercontent.com/docs/securesc/q855d61ksk3m8tv96m4m8sfhkg46l2vh/bo2s7uh60o62ia0qkhaof5q96s0ev3d6/1629899175000/06049624160957438625/15222733518293580913Z/1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p?e=download [following]\n",
            "--2021-08-25 13:46:26--  https://doc-04-84-docs.googleusercontent.com/docs/securesc/q855d61ksk3m8tv96m4m8sfhkg46l2vh/bo2s7uh60o62ia0qkhaof5q96s0ev3d6/1629899175000/06049624160957438625/15222733518293580913Z/1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p?e=download\n",
            "Resolving doc-04-84-docs.googleusercontent.com (doc-04-84-docs.googleusercontent.com)... 142.250.141.132, 2607:f8b0:4023:c0b::84\n",
            "Connecting to doc-04-84-docs.googleusercontent.com (doc-04-84-docs.googleusercontent.com)|142.250.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=jl6ur58g87p0c&continue=https://doc-04-84-docs.googleusercontent.com/docs/securesc/q855d61ksk3m8tv96m4m8sfhkg46l2vh/bo2s7uh60o62ia0qkhaof5q96s0ev3d6/1629899175000/06049624160957438625/15222733518293580913Z/1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p?e%3Ddownload&hash=dq1o6t55t1so78qna3hjci30j1qso9ht [following]\n",
            "--2021-08-25 13:46:27--  https://docs.google.com/nonceSigner?nonce=jl6ur58g87p0c&continue=https://doc-04-84-docs.googleusercontent.com/docs/securesc/q855d61ksk3m8tv96m4m8sfhkg46l2vh/bo2s7uh60o62ia0qkhaof5q96s0ev3d6/1629899175000/06049624160957438625/15222733518293580913Z/1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p?e%3Ddownload&hash=dq1o6t55t1so78qna3hjci30j1qso9ht\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.2.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-04-84-docs.googleusercontent.com/docs/securesc/q855d61ksk3m8tv96m4m8sfhkg46l2vh/bo2s7uh60o62ia0qkhaof5q96s0ev3d6/1629899175000/06049624160957438625/15222733518293580913Z/1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p?e=download&nonce=jl6ur58g87p0c&user=15222733518293580913Z&hash=aen9ada1r41quk6n7etil827r69c8bfg [following]\n",
            "--2021-08-25 13:46:27--  https://doc-04-84-docs.googleusercontent.com/docs/securesc/q855d61ksk3m8tv96m4m8sfhkg46l2vh/bo2s7uh60o62ia0qkhaof5q96s0ev3d6/1629899175000/06049624160957438625/15222733518293580913Z/1tKOTjbtdxS-pzw80JHN-2FUiZA7htL7p?e=download&nonce=jl6ur58g87p0c&user=15222733518293580913Z&hash=aen9ada1r41quk6n7etil827r69c8bfg\n",
            "Connecting to doc-04-84-docs.googleusercontent.com (doc-04-84-docs.googleusercontent.com)|142.250.141.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip-compressed]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip                [       <=>          ] 743.54M  71.4MB/s    in 21s     \n",
            "\n",
            "2021-08-25 13:46:48 (34.9 MB/s) - ‘data.zip’ saved [779657414]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUIZqU4eyCsu",
        "outputId": "20a81fba-ef3f-4f6e-e352-57b8b6f7ac7d"
      },
      "source": [
        "import os\n",
        "\n",
        "!mkdir '../input'\n",
        "print(os.listdir(\"../input\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoYTjspwyaw0",
        "outputId": "83eeaa57-f2e9-4c5a-f0e4-dfcda3b567f1"
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "  inflating: Annotation.zip          \n",
            "  inflating: all-dogs.zip            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q49lR-UJycsa"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "!mkdir '../input/annotation'\n",
        "\n",
        "with zipfile.ZipFile(\"Annotation.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"../input/annotation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXXmvlKsycc6"
      },
      "source": [
        "!mkdir '../input/all-dogs'\n",
        "\n",
        "with zipfile.ZipFile(\"all-dogs.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"../input/all-dogs\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbaHeJMaxkr1"
      },
      "source": [
        "# Generative Adversarial Network \n",
        "# Šta je GAN?\n",
        "\n",
        "GAN je generativna kontradiktorna mreža - generativni model koji u sebi koristi modele generator i diskriminator kako bi generisao nove fotografije.\n",
        "Ova dva modela međusobno utiču jedan na drugi.\n",
        "Generisaće se nove fotografije u odnosu na distribuciju iz podataka dataseta.\n",
        "\n",
        "# Kako funkcioniše GAN?\n",
        "Prvenstveno je potrebno odabrati dataset (slike pasa), diskriminatoru dati podatke da ih prouči (kako bi mogao odrediti šta je pravi pas), ovde generator kao ulaz uzima random vektor (buka, skup brojeva) i generiše nove fotografije, diskriminator sad treba da odluči da li je fotografija prava ili lažna, tj. generisana.\n",
        "Na izlazu se dobijaju vrednosti pomoću kojih se optimizuje rad oba modela.\n",
        "Generator će generisati bolje fotografije, a diskriminator će davati bolju prognozu da li je fotografija prava ili ne.\n",
        "Ovaj proces se dešava iterativno kroz određeni broj epoha treniranja modela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uL4K7a2Hxkr2",
        "outputId": "0eaa63c7-7835-492a-a160-ee36f3e684e3"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "import argparse\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "import torchvision.utils as vutils\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "manualSeed = 999\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f709e2d42b0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsT59E8Gxkr2"
      },
      "source": [
        "\n",
        "   * dataroot - putanja do dataset foldera.\n",
        "   * workers - broj worker thread-ova za učitavanje podataka preko DataLoader-a\n",
        "   * batch_size - veličina skupa koji će se koristiti u treniranju modela. Istraživanja na DCGAN temu pokazuju da je najbolje koristiti 128\n",
        "   * image_size - veličina fotografije koja se koristi u treniranju. Implementacija je urađena za fotografije veličine 64x64. Ukoliko želimo drugu veličinu, implementacija D i G se mora menjati.\n",
        "   * nc - broj kanala za boje u fotografijama. Za fotografije u boji ovo će biti 3\n",
        "   * nz - length of latent vector\n",
        "   * ngf - relates to the depth of feature maps carried through the generator\n",
        "   * ndf - sets the depth of feature maps propagated through the discriminator\n",
        "   * num_epochs - broj epoha za treniranje. Duže treniranje će dati bolje rezultate, ali će i dosta duže trajati\n",
        "   * lr - learning rate for training. As described in the DCGAN paper, this number should be 0.0002\n",
        "   * beta1 - beta1 hyperparameter for Adam optimizers. As described in paper, this number should be 0.5\n",
        "   * ngpu - number of GPUs available. If this is 0, code will run in CPU mode. If this number is greater than 0 it will run on that number of GPUs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb4XcPKhxkr3"
      },
      "source": [
        "dataroot = '../input/all-dogs'\n",
        "workers = 2\n",
        "batch_size = 128\n",
        "image_size = 64\n",
        "nc = 3\n",
        "nz = 100\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "num_epochs = 300\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "ngpu = 1\n",
        "ComputeLB = False\n",
        "DogsOnly = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHHZ-gqjxkr3"
      },
      "source": [
        "import numpy as np, pandas as pd, os\n",
        "import xml.etree.ElementTree as ET \n",
        "import matplotlib.pyplot as plt, zipfile \n",
        "from PIL import Image \n",
        "from glob import glob\n",
        "\n",
        "ROOT = '../input/generative-dog-images/'\n",
        "if not ComputeLB: ROOT = '../input/'\n",
        "IMAGES = os.listdir(ROOT + 'all-dogs/all-dogs/')\n",
        "breeds = os.listdir(ROOT + 'annotation/Annotation/') \n",
        "\n",
        "idxIn = 0; namesIn = []\n",
        "imagesIn = np.zeros((25000,64,64,3))\n",
        "\n",
        "# iseci fotografije uz pomoć anotacija\n",
        "# https://www.kaggle.com/paulorzp/show-annotations-and-breeds\n",
        "if DogsOnly:\n",
        "    for breed in breeds:\n",
        "        for dog in os.listdir(ROOT+'annotation/Annotation/'+breed):\n",
        "            try: img = Image.open(ROOT+'all-dogs/all-dogs/'+dog+'.jpg') \n",
        "            except: continue           \n",
        "            tree = ET.parse(ROOT+'annotation/Annotation/'+breed+'/'+dog)\n",
        "            root = tree.getroot()\n",
        "            objects = root.findall('object')\n",
        "            for o in objects:\n",
        "                bndbox = o.find('bndbox') \n",
        "                xmin = int(bndbox.find('xmin').text)\n",
        "                ymin = int(bndbox.find('ymin').text)\n",
        "                xmax = int(bndbox.find('xmax').text)\n",
        "                ymax = int(bndbox.find('ymax').text)\n",
        "                w = np.min((xmax - xmin, ymax - ymin))\n",
        "                img2 = img.crop((xmin, ymin, xmin+w, ymin+w))\n",
        "                img2 = img2.resize((64,64), Image.ANTIALIAS)\n",
        "                imagesIn[idxIn,:,:,:] = np.asarray(img2)\n",
        "                #if idxIn%1000==0: print(idxIn)\n",
        "                namesIn.append(breed)\n",
        "                idxIn += 1\n",
        "    idx = np.arange(idxIn)\n",
        "    np.random.shuffle(idx)\n",
        "    imagesIn = imagesIn[idx,:,:,:]\n",
        "    namesIn = np.array(namesIn)[idx]\n",
        "    \n",
        "# random iseci sve fotografije\n",
        "else:\n",
        "    x = np.random.choice(np.arange(20579),10000)\n",
        "    for k in range(len(x)):\n",
        "        img = Image.open(ROOT + 'all-dogs/all-dogs/' + IMAGES[x[k]])\n",
        "        w = img.size[0]\n",
        "        h = img.size[1]\n",
        "        sz = np.min((w,h))\n",
        "        a=0; b=0\n",
        "        if w<h: b = (h-sz)//2\n",
        "        else: a = (w-sz)//2\n",
        "        img = img.crop((0+a, 0+b, sz+a, sz+b))  \n",
        "        img = img.resize((64,64), Image.ANTIALIAS)   \n",
        "        imagesIn[idxIn,:,:,:] = np.asarray(img)\n",
        "        namesIn.append(IMAGES[x[k]])\n",
        "        if idxIn%1000==0: print(idxIn)\n",
        "        idxIn += 1\n",
        "    \n",
        "# prikaz isečenih slika\n",
        "x = np.random.randint(0,idxIn,25)\n",
        "for k in range(5):\n",
        "    plt.figure(figsize=(15,3))\n",
        "    for j in range(5):\n",
        "        plt.subplot(1,5,j+1)\n",
        "        img = Image.fromarray( imagesIn[x[k*5+j],:,:,:].astype('uint8') )\n",
        "        plt.axis('off')\n",
        "        if not DogsOnly: plt.title(namesIn[x[k*5+j]],fontsize=11)\n",
        "        else: plt.title(namesIn[x[k*5+j]].split('-')[1],fontsize=11)\n",
        "        plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udMTZgTOxkr3"
      },
      "source": [
        "# učitavanje dataseta\n",
        "dataset = dset.ImageFolder(root=dataroot,\n",
        "                           transform=transforms.Compose([\n",
        "                               transforms.Resize(image_size),\n",
        "                               transforms.CenterCrop(image_size),\n",
        "                               transforms.ToTensor(),\n",
        "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbMovG1VaE8g"
      },
      "source": [
        "# Implementacija\n",
        "\n",
        "Nakon definisanja parametara i učitavanja dataseta, može se početi sa implementacijom. Počećemo sa strategijom inicijalizacije težina, zatim ćemo proći kroz generator, diskriminator, funkcije gubitka i treniranje modela."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu5YN1WZaJ3u"
      },
      "source": [
        "\n",
        "# Inicijalizacija težina\n",
        "\n",
        "U DCGAN istraživanju, \n",
        "autori su zaključili da sve težine modela treba da budu random inicijalizovane iz normalne distribucije sa parametrima mean-0, stdev-0.02.\n",
        "Funkcija weights_init uzima inicijalizovani model kao ulaz i reinicijalizuje sve konvolucijske, konvoluciono-transpozicione i batch normalizacijske slojeve da zadovolji kriterijume. Ova funkcija se primenjuje na modele odmah nakon inicijalizacije."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP9IlL8axkr4"
      },
      "source": [
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv') != -1:\n",
        "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "  elif classname.find('BatchNorm') != -1:\n",
        "    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "    nn.init.normal_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUVINUM2xkr4"
      },
      "source": [
        "# Generator\n",
        "\n",
        "Generator, G,\n",
        " je dizajniran da mapira latentni vektor prostora (z) u prostor podataka. Pošto su naši podaci fotografije, konvertovanje z u prostor podataka znači kreirati RGB fotografiju istih dimenzija kao naši trening podaci (npr. 3x64x64).\n",
        "\n",
        "U praksi, ovo je postignuto pomoću serije dvodimenzionih konvolucijskih transpozicionih slojeva, svaki uparen sa 2D batch normalizacionim slojem i ReLu aktivacijom.\n",
        "\n",
        "Izlaz iz generatora se pušta kroz tanh funkciju i vraća kao vrednost između [-1, 1].\n",
        "\n",
        "Vrlo je bitno da postoje batch norm. funkcije posle conv-transpore slojeva (Po istraživanju o DCGAN-ovima).\n",
        "Ovi slojevi pomažu flow-u gradijenata tokom treniranja.\n",
        "\n",
        "Na fotografiji ispod je prikazan DCGAN:\n",
        "\n",
        "<img src=\"https://pytorch.org/tutorials/_images/dcgan_generator.png\" width=800>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnWT2rZaxkr4"
      },
      "source": [
        "# definisanje generatora (2d conv-transpose -> batch norm -> relu -> 4 convolutions)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            \n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            \n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aS2B5BYxkr4"
      },
      "source": [
        "netG = Generator(ngpu).to(device)\n",
        "netG.apply(weights_init)\n",
        "print(netG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLimL8Puxkr4"
      },
      "source": [
        "# Diskriminator\n",
        "\n",
        "Diskriminator, D,\n",
        "je binarna klasifikaciona mreža koja uzima fotografiju kao ulaz i na izlazu daje verovatnoću da je ulazna fotografija prava (da nije generisana).\n",
        " Ovde, D uzima 3x64x64 ulaznu fotografiju, procesuira je kroz seriju 2D konvolucije, 2D batch normalizacije, i LeakyReLU slojeva, i na izlazu daje verovatnoću uz pomoć Sigmoid aktivacione funkcije.\n",
        " Ova arhitektura može biti proširena sa još slojeva ukoliko je to potrebno, iako ne bi bilo korisno u Conv2d, batch norm. ili LeakyReLU.\n",
        "\n",
        "**DCGAN istraživanje spominje da je dobra praksa koristiti 2d konvoluciju umesto pooling-a za downsampl-ovanje fotografija jer omogućava da mreža uči iz svoje pooling funkcije.**\n",
        "\n",
        "**Takođe, batch normalizacija i leaky relu funkcije promovišu bolji gradient flow što je ključno za proces učenja i G i D.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZRq3Nvoxkr5"
      },
      "source": [
        "# definisanje diskriminatora (2d conv - batch norm - leaky relu - 4 konvolucije - sigmoid funkcija za verovatnoću)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            \n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4dDg-Z2xkr5"
      },
      "source": [
        "netD = Discriminator(ngpu).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fVJVwUYxkr5"
      },
      "source": [
        "# Funkcija gubitka i optimizatori\n",
        "\n",
        "Kada su definisani G i D,\n",
        "možemo specifirati kako će učiti kroz funkcije gubitka i optimizatore. Koristićemo **binary cross entropy loss funkciju (BCELoss)** koja je u pytorch-u definisana kao:\n",
        "\n",
        "`ℓ(x, y) = L = {l1, …, lN}^⊤,`\n",
        "\n",
        "`ln= −[yn ⋅ logxn + (1 − yn) ⋅ log(1−xn)]`\n",
        "\n",
        "Ova funkcija nudi kalkulaciju obe logaritamske komponente (npr. log(D(x)) i log(1 - D(G(z))) ).\n",
        "Specifiraćemo koji deo BCE jednačine ćemo koristiti sa y ulazom. Ovo će biti izvršeno kroz petlju treniranja. Izmenom y parametra,, biramo koju komponentu želimo da izračunamo.\n",
        "\n",
        "Dalje, želimo da definišemo labelu za prave slike sa 1, dok za izgenerisane želimo da koristimo 0.\n",
        "Ove labele će biti korišćene pri kalkulaciji gubitka D i G, a takođe je ovo i konvencija u originalnom GAN istraživanju.\n",
        "Na kraju, definišemo dva odvojena optimizatora, za D i G po jedan. Kao što je navedeno u DCGAN istraživanju, oba će koristiti optimizator Adam sa parametrima:\n",
        "\n",
        "```\n",
        "learning rate - 0.0002 i\n",
        "beta1 - 0.5\n",
        "```\n",
        "\n",
        "Za čuvanje progresije učenja, generisaćemo fiksni skup latentnih vektora koji se iscrtavaju iz Gaussian distribucije (npr. **fixed_noise**).\n",
        "U petlji treniranja, periodično ćemo unositi ovaj fixed_noise u G, i tokom iteracija ćemo videti fotografije generisane iz ove buke."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0gxuwytxkr5"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "real_label = 1\n",
        "fake_label = 0\n",
        "\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OehxCHK3xkr5"
      },
      "source": [
        "# Treniranje\n",
        "\n",
        "Konačno, imamo sve delove GAN framework-a definisane, sada može da se pređe na treniranje modela.\n",
        "Vrlo je bitno paziti na hiperparametre, jer pogrešna vrednost za njihova podešavanja mogu dovesti do pucanja programa bez ikakvog objašnjena.\n",
        "\n",
        "Ovde ćemo pažljivo pramitit Algoritam 1 iz Goodfellow-ovog istraživanja, dok pratimo najbolje prakse prikazane na ovom [repozitorijumu](https://github.com/soumith/ganhacks).\n",
        "Konstruisaćemo različite mini skupove za prave i lažne fotografije, kao i podešavati G izlaznu funkciju da se maksimizuje logD(G(z)).\n",
        "\n",
        "Treniranje je podeljeno u dva glavna koraka. \n",
        "Korak 1 - ažurira diskriminator,\n",
        "Korak 2 - ažurira generator\n",
        "\n",
        "* **Korak 1 - Treniranje diskriminatora**\n",
        "\n",
        "Cilj treniranja diskriminatora jeste da maksimizuje verovatnoću da pogodi klasifikaciju fotografije da li je prava ili lažna.\n",
        "Želimo da ažuriramo diskriminator tako što ćemo podići njegov stohastički gradijent (Goodfellow).\n",
        "Drugim rečima, želimo da maksimizujemo\n",
        "\n",
        "```\n",
        "log(D(x)) + log(1 − D(G(z)))\n",
        "```\n",
        "\n",
        "Računaćemo ovo u dva koraka, zbog sugestija sa ganhacks repozitorijuma - separacija mini skupova.\n",
        "Prvo, konstruisaćemo skup uzoraka pravih fotografija iz trening seta, proslediti ih kroz D, izračunati gubitak (**log(D(x))**), zatimm iskalkulisati gradijent u prolasku unazad.\n",
        "Drugo, konstruisaćemo skup lažnih fotografija u generatoru, proslediti ovaj skup kroz D, izračunati gubitak (**log(1 - D(G(z)))**), i akumuliraćemo gradijente kroz prolaske unazad.\n",
        "Kada su gradijenti prikupljeni iz oba koraka (iz skupova pravih i lažnih fotografija), optimizovaćemo diskriminator.\n",
        "\n",
        "* **Korak 2 - Treniranje generatora**\n",
        "\n",
        "Kao što je navedeno u originalnom istraživanju, želimo da treniramo G tako što ćemo minimizovati log(1 - D(G(z))) u pokušaju da generišemo bolje lažne fotografije.\n",
        "Goodfellow je ukazao na to da ova metoda ne daje dobre rezultate (gradijente), pogotovo rano u procesu učenja.\n",
        "Kao rešenje, umesto toga ćemo hteti da maksimizujemo log(D(G(z))).\n",
        "U kodu ovo će se sprovesti kroz klasifikaciju izlaza iz generatora iz prvog koraka u diskriminatoru, kalkulisanje gubitka G, kalkulisanje gradijenta G u prolasku unazad i konačno ažuriranje parametara G u koraku optimizacije.\n",
        "\n",
        "Koristićemo prave labele za funkciju gubitka, i to će nam omogućiiti da koristimo log(x) deo funkcije BCELoss, umesto log(1-x).\n",
        "\n",
        "Na kraju, kada se završi svaka epoha, guraćemo naš skup fixed_noise u generator da vizuelno pratimo progresiju treniranja G.\n",
        "Statistike treniranja koje ćemo prikazati su:\n",
        "\n",
        "* **Loss_D** - gubitak diskriminatora koji se izračunava kao suma svih gubitaka za skupove pravih i lažnih fotografija.\n",
        "\n",
        "`(log(D(x))+log(D(G(z)))`\n",
        "\n",
        "* **Loss_G** - gubitak generatora izračunat kao\n",
        "\n",
        "`log(D(G(z)))`\n",
        "\n",
        "* **D(x)** - prosečan izlaz (u skupu) iz diskriminatora za skup pravih fotografija. Vrednost će početi blizu 1 i teoretski bi konvergiralo vrednosti 0.5 kada G postane bolji.\n",
        "\n",
        "* **D(G(z))** - prosečan izlaz za skup lažnih slika. Prva vrednost je pre nego što je D ažuriran, a druga vrednost nakon ažuriranja D.\n",
        "Vrednost će početi blizu 0 i konvergiraće ka 0.5 kada G postane bolji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va9seWTixkr6"
      },
      "source": [
        "# Lista za praćenje progresa\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# Za svaku epohu\n",
        "for epoch in range(num_epochs):\n",
        "    # Za svaki skup u dataloaderu\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Treniranje sa skupom pravih fotografija\n",
        "        netD.zero_grad()\n",
        "        # Formatiranje skupa\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, device=device, dtype=torch.float)\n",
        "        # Prosleđivanje skupa pravih fotografija kroz D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Izračunati gubitak na skupu pravih fotografija\n",
        "        errD_real = criterion(output, label)\n",
        "        # Izračunati gradijente D u prolasku unazad\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Treniranje sa skupom lažnih fotografija\n",
        "        # Generisanje skupa latentnih vektora\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generisanje skupa lažnih slika pomoću G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Klasifikacija skupa lažnih slika pomoću D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Izračunati gubitak D u skupu lažnih slika\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Izračunati gradijente D u skupu lažnih slika\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Sumiranje gradijenata iz skupova pravih i lažnih slika\n",
        "        errD = errD_real + errD_fake\n",
        "        # Ažuriranje D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label) # labela za lažne fotografije će biti labela pravih fotografija za generator\n",
        "        # Zbog ažuriranja D, izvrši prolazak unapred za skup lažnih slika kroz D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Izračunati gubitak G baziran na ovom izlazu\n",
        "        errG = criterion(output, label)\n",
        "        # Izračunati gradijente G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Ažuriranje G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Statistika izlaza treniranja\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "        # Čuvanje gubitka za plotovanje kasnije\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Provera generatora čuvanjem izlaza G uz fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNJkGe28xkr6"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APlETbtVxkr6"
      },
      "source": [
        "# Izgenerisane fotografije"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIFXjhpxxkr6"
      },
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)))] for i in img_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Chrz7_btxkr6"
      },
      "source": [
        "if not os.path.exists('../output_images'):\n",
        "    os.mkdir('../output_images')\n",
        "im_batch_size = 50\n",
        "n_images=10000\n",
        "for i_batch in range(0, n_images, im_batch_size):\n",
        "    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n",
        "    gen_images = netG(gen_z)\n",
        "    images = gen_images.to(\"cpu\").clone().detach()\n",
        "    images = images.numpy().transpose(0, 2, 3, 1)\n",
        "    for i_image in range(gen_images.size(0)):\n",
        "        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))\n",
        "\n",
        "\n",
        "import shutil\n",
        "shutil.make_archive('images', 'zip', '../output_images')\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8Arb_GzoLIQ"
      },
      "source": [
        "Napravljeni su rezultati tokom korišćenja 100 i 200 epoha, i njihovim poređenjem može se videti napredak u učenju ovog modela.\n",
        "Sa brojem od 300 epoha, collab je izbacivao grešku preopterećenja resursa, jer ovo treniranje zahteva dosta vremena.\n",
        "Rezultati su okačeni na github repozitorijumu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyUBQzIjxkr6"
      },
      "source": [
        "# Reference\n",
        "\n",
        "* Zasnovan na pytorch DCGAN tutorijalu [pytorch documentation - DCGAN](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html)\n",
        "\n",
        "* Najbolje prakse - [ganhacks](https://github.com/soumith/ganhacks)\n",
        "\n",
        "* [DCGAN istraživanje](https://arxiv.org/pdf/1511.06434v2.pdf)\n",
        "\n",
        "* Kod preuzet sa [kaggle notebook](https://www.kaggle.com/rajwardhanshinde/simple-dcgan-pytorch/execution)\n",
        "\n",
        "# Korisni linkovi:\n",
        "\n",
        "* [Dataset Stanford Dog Images](http://vision.stanford.edu/aditya86/ImageNetDogs/)\n",
        "\n",
        "* [Youtube GAN Computerphile](https://www.youtube.com/watch?v=Sw9r8CL98N0)\n",
        "\n",
        "* [Youtube GAN Stanford University](https://www.youtube.com/watch?v=5WoItGTWV54)\n",
        "\n",
        "* [wget sa drive-a](https://gist.github.com/iamtekeste/3cdfd0366ebfd2c0d805)\n",
        "\n",
        "* [učitavanje dataseta i transformacije](https://www.kaggle.com/bitthal/understanding-input-data-and-loading-with-pytorch)\n",
        "\n",
        "* [tehnike za optimizovanje GAN-ova](https://www.kaggle.com/jadeblue/dcgans-and-techniques-to-optimize-them)"
      ]
    }
  ]
}